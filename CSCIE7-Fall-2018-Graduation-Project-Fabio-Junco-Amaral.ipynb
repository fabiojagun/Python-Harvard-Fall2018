{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fabio Junco Amaral\n",
    "## Harvard Extensions School, Fall 2018 \n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will now start investigating some data from Boston \n",
    "\n",
    "# We will do a lot of data wrangling based on the CSV file found at (https://data.boston.gov/dataset/food-establishment-inspections)\n",
    "\n",
    "## Lets start importing some libraries that will help us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd # For data manipulation and analysis\n",
    "import matplotlib.pyplot as plt # Better plots\n",
    "from itertools import groupby\n",
    "\n",
    "# Using the 'inline', my matplotlib graphs will be included in my notebook, next to the code\n",
    "% matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will now read the file, and rename some columns, so we can have a common code (and following PEP8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mayorsfoodcourt.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "\n",
    "df_food = df.rename(index=str, columns={'LICENSENO': 'license_num', 'LICSTATUS': 'license_st', 'DESCRIPT': 'biz_ype', \n",
    "                             'ViolLevel': 'violation_lvl', 'ViolDesc': 'violation_desc', 'ZIP': 'zip', \n",
    "                              'VIOLDTTM': 'violation_date', 'ViolStatus': 'violation_st'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look our dataframe now\n",
    "# The tail() shows by default the last five rows\n",
    "df_food.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is too much information in this dataframe, lets get rid of some columns that we will not use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food = df_food.drop(['businessName', 'DBAName', 'LegalOwner', 'NameLast', 'RESULT', 'RESULTDTTM', 'NameFirst',\n",
    "              'LICENSECAT', 'Comments', 'STATE', 'Property_ID', 'Violation', 'StatusDate', \n",
    "              'Location', 'ISSDTTM', 'EXPDTTM', 'Address', 'CITY'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we have More data wrangling to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food['zip'] = df_food['zip'].astype(str)  # We need the zipcode to be a string, to easily manipulate its values\n",
    "df_food = df_food[df_food['zip'].map(len) >= 4]  # There are many invalid zips, we will map only the 4 last digits\n",
    "df_food['zip'] = df_food['zip'].astype(int)  # Turning the zip into ints again\n",
    "df_food = df_food[df_food['violation_st'] != ' ']  # We will remove whitespaces from violation_st\n",
    "df_food = df_food[df_food['violation_lvl'] != ' ']  # We will remove whitespaces from violation_lvl\n",
    "df_food = df_food[df_food['license_st'] != 'Deleted']  # We will remove invalid values from license_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most of the work when we are dealing with data is cleaning so we can better use it. We can clean and modified as much as we want to. Here is a quote about data wrangling:\n",
    "\n",
    "### \"Data wrangling is the process of gathering, selecting, and transforming data to answer an analytical question.  Also known as data cleaning or “munging”, legend has it that this wrangling costs analytics professionals as much as 80% of their time, leaving only 20% for exploration and modeling. Why does it take so long to wrangle the data so that it is usable for analytics?\"\n",
    "https://www.elderresearch.com/blog/what-is-data-wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After all that, we will filter for business located in Boston.\n",
    "### We found the valid Boston Zip codes in this [website](http://www.city-data.com/zipmaps/Boston-Massachusetts.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_zip = ['2108', '2109', '2110', '2111', '2113', '2114', '2115', '2116', '2118', '2119', '2120', '2121', \n",
    "              '2122', '2124', '2125', '2126', '2127', '2128', '2129', '2130', '2131', '2132', '2133', '2134', \n",
    "              '2135', '2136', '2163', '2199', '2203', '2210', '2215', '2222']\n",
    "\n",
    "df_food = df_food[df_food.zip.isin(boston_zip)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alright, now lets start creating some plots\n",
    "\n",
    "### First, how many violations have Passed or Fail (keep in mind that each business have multiple violations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create that will count all values from violation_st creating an index\n",
    "ind = df_food['violation_st'].value_counts().index\n",
    "# Now we will plot this column, counting the values\n",
    "df_food['violation_st'].value_counts()[ind].plot(kind='bar', figsize=(6, 6));\n",
    "\n",
    "# A good chart must have labels telling you what it is showing to you\n",
    "plt.xlabel('Violation Status')\n",
    "plt.ylabel('Number of Violations')\n",
    "plt.title('Number of Violation per Violation Status');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It looks like we have more Fails than Passes\n",
    "\n",
    "### Let's check the level of severity of these violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = df_food['violation_lvl'].value_counts().index\n",
    "df_food['violation_lvl'].value_counts()[ind].plot(kind='bar', figsize=(6, 6));\n",
    "\n",
    "plt.xlabel('Violation Level')\n",
    "plt.ylabel('Number of Violations')\n",
    "plt.title('Number of Violation per Violation Level');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets check more about the Violations that Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a new dataframe, only with the violation_st that is 'Fail'\n",
    "df_fail = df_food[df_food['violation_st'] == 'Fail']\n",
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "explode = (0, 0.1, 0) # only \"explode\" the 2nd slice\n",
    "labels = '* = Low', '*** = Severe', '** = Medium'  # It is ordered, so we have to put the labels in order too\n",
    "\n",
    "ind = df_fail['violation_lvl'].value_counts().index\n",
    "df_fail['violation_lvl'].value_counts()[ind].plot(kind='pie', figsize=(10, 10), labels=labels, explode=explode, \n",
    "                                                  autopct='%1.1f%%', shadow=True,  startangle=90);\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Percentage of Violation Level by Failed Violations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly see the same graph for violation_st that is 'Pass'\n",
    "df_pass = df_food[df_food['violation_st'] == 'Pass']\n",
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "explode = (0, 0.1, 0) # only \"explode\" the 2nd slice\n",
    "labels = '* = Low', '*** = Severe', '** = Medium'  # It is ordered, so we have to put the labels in order too\n",
    "\n",
    "ind = df_pass['violation_lvl'].value_counts().index\n",
    "df_pass['violation_lvl'].value_counts()[ind].plot(kind='pie', figsize=(10, 10), labels=labels, explode=explode, \n",
    "                                                  autopct='%1.1f%%', shadow=True,  startangle=90);\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Percentage of Violation Level by Failed Violations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So almost 20% of the violations that failed are severe. Lets dig more into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a new dataframe (based on the dataset with on fails), only violation_lvl equal '*** (severe)\n",
    "df_fail_severe = df_fail[df_fail['violation_lvl'] == '***']\n",
    "\n",
    "# The head() shows by default the first five rows, but lets check only the last 2 rows\n",
    "df_fail_severe.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where in the city of Boston are those violations happening? We will check the Fails that are Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = df_fail_severe['zip'].value_counts().index\n",
    "df_fail_severe['zip'].value_counts()[ind].plot(kind='bar', figsize=(12, 12));\n",
    "\n",
    "plt.xlabel('Boston Zip Code')\n",
    "plt.ylabel('Severe Violations Fail')\n",
    "plt.title('Severe Violations Fail by Boston Zip Code');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Zip Code that has more fails (more than severe 4000 violations) is in the Zip Code 2116.\n",
    "### If we look for this zip, we find that this is the Back Bay area. Maybe because there is a lot of restaurants and business in that area, a lot of old houses? We can try to conclude WHY we have such a high number of severe cases there.\n",
    "\n",
    "### What if we dig even deeper into this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataframe, only with zipcode 2116\n",
    "df_fail_severe_2116 = df_fail_severe[df_fail_severe['zip'] == 2116]\n",
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "explode = (0, 0.1) # only \"explode\" the 2nd slice\n",
    "\n",
    "ind = df_fail_severe_2116['license_st'].value_counts().index\n",
    "df_fail_severe_2116['license_st'].value_counts()[ind].plot(kind='pie', figsize=(10, 10), explode=explode, \n",
    "                                                  autopct='%1.1f%%', shadow=True,  startangle=90);\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Percentage of Violation Level by Failed Violations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So it looks like almost 70% of those businesses are still Actives\n",
    "\n",
    "\n",
    "## This is just an example of what we can do with a dataset. We can gather pieces of information and conclusions based on data.\n",
    "## I personally find Graphs amazing, they can tell so much just by looking by then and trying to get what they are telling us.\n",
    "\n",
    "## Pandas, Numpy and Matplotlib are amazing, and they can offer MUCH more than I've used here. I will now give some random examples of cool stuff we can do with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining different data in one graph\n",
    "\n",
    "# We can manipulate the size of our graph with this call\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Plotting two graphs\n",
    "# It's possible to modify the kind of the plot (pie chart, bar, line etc), width, color, labels and MUCH more\n",
    "df_fail.groupby('license_st').violation_lvl.value_counts().plot(kind='bar', color='r', label='FAIL', \n",
    "                                                                zorder=10, linewidth=5.0)\n",
    "df_pass.groupby('license_st').violation_lvl.value_counts().plot(kind='line', color='g', label='PASS', \n",
    "                                                                zorder=15, linewidth=5.0)\n",
    "\n",
    "\n",
    "# Creating a label box outside the chart\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel('License Status')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Combination of Active and Inactive License status with Violation Severity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph custozimation is almost endless. We will modify this graph as much as we can (not too worried with information\n",
    "# displayed, we will get crazy)\n",
    "\n",
    "# Manipulating ploting parameter separeted\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "colors_x = ['#2AAF33', '#002B00', '#004600']\n",
    "colors_y = ['#FF4D3A', '#CB0707', '#FF1800']\n",
    "labels = '* = Low', '*** = Severe', '** = Medium'  # It is ordered, so we have to put the labels in order too\n",
    "\n",
    "indx = df_fail['violation_lvl'].value_counts().index\n",
    "x = df_fail['violation_lvl'].value_counts()[indx]\n",
    "\n",
    "indy = df_pass['violation_lvl'].value_counts().index\n",
    "y = df_pass['violation_lvl'].value_counts()[indy]\n",
    " \n",
    "# Plot\n",
    "plt.pie(y, colors=colors_y, autopct='%1.1f%%', pctdistance=0.85, startangle=180, labeldistance=1.08, radius=1,\n",
    "        labels=labels)\n",
    "plt.pie(x, colors=colors_x, autopct='%1.5f%%', pctdistance=0.85, startangle=180, radius=0.75, frame=True)\n",
    "\n",
    "# Creating a doughnut style chart\n",
    "centre_circle = plt.Circle((0,0),0.5,color='black', fc='white',linewidth=0)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    " \n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# A scatter plot is a type of plot that shows the data as a collection of points. The position of a point depends \n",
    "# on its two-dimensional value, where each value is a position on either the horizontal or vertical dimension. \n",
    "plt.scatter(df_fail['zip'], df_fail['license_num'], c=\"purple\", alpha=0.5, marker='x', label=\"X\")\n",
    "\n",
    "plt.xlabel(\"Number\")\n",
    "plt.ylabel(\"Zip\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORDER MATTERS!!!\n",
    "\n",
    "# The same code as before, but we will change then posisiton of some lines\n",
    "\n",
    "# plt.figure(figsize=(15, 15)) <- This code will go below\n",
    "\n",
    "plt.scatter(df_fail['zip'], df_fail['license_num'], c=\"purple\", alpha=0.5, marker='x', label=\"X\")\n",
    "\n",
    "plt.figure(figsize=(5, 5))  # <- here it is\n",
    "\n",
    "plt.xlabel(\"Number\")\n",
    "plt.ylabel(\"Zip\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We also can do everything we can with python in this dataframe, anything to help debug, wrangling data and whatever our imagination let us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in df_fail_severe_2116:\n",
    "    print(columns, type(columns), len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets talk a little about Markdowns \n",
    "> ## <font color=green>They are one of the most important parts of our notebook</font>\n",
    "***\n",
    "### We need to be as clear as possible in our graphs and explanations\n",
    "#### So why not use words to do it?\n",
    "\n",
    "- Customize\n",
    "- Be __bold__\n",
    "    - But no _too_ much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Now, before we finish, I would like to point out some limitations of the project and how to address them in the future. The main issue was the SIZE of the dataframe. It had almost 550 thousand rows and 26 columns. This is a very big dataframe.\n",
    "### Even after I've done some data cleaning, I'd still had a big dataframe.\n",
    "### So this was a problem because some graphs I was trying to do took so much time that I decided to not put them into this project. I believe that I need to use NumPy in the future because NumPy can greatly improve my performance issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you for your time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
